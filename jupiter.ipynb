{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sly\r\n",
    "import codecs\r\n",
    "\r\n",
    "class Lexer(sly.Lexer):\r\n",
    "    \r\n",
    "    tokens = {\r\n",
    "        ASSIGN, EQ, LT, LE, GT, GE, NE,\r\n",
    "        ID, INTEGER, STRING, LET, READ, DATA, PRINT, GOTO, IF, THEN, ELSE, FOR, NEXT, TO, STEP, END,\r\n",
    "        STOP, GOSUB, DIM, RETURN, RUN, INPUT, OR, AND, NOT, AS,\r\n",
    "        OPEN, CLOSE, POKE, RESTORE, SYS, WAIT, OUPUT, CR, LF, REM\r\n",
    "    }\r\n",
    "\r\n",
    "    literals = { '+','-','*','/','(', ')', ',', ';', '#', ':', '^' }\r\n",
    "    \r\n",
    "    ignore = ' \\t'\r\n",
    "    \r\n",
    "    EQ = r'=='\r\n",
    "    ASSIGN = r'='\r\n",
    "    NE = r'<>'\r\n",
    "    LE = r'<='\r\n",
    "    LT = r'<'\r\n",
    "    GE = r'>='\r\n",
    "    GT = r'>'\r\n",
    "\r\n",
    "    STRING = r'\\\".*?\\\"'\r\n",
    "    CR = r'\\r+'\r\n",
    "    LF = r'\\n+'\r\n",
    "    REM = r'REM.[^\\r]*'\r\n",
    "\r\n",
    "    @_(r'[a-zA-Z_][a-zA-Z0-9_]*\\$?')\r\n",
    "    def ID(self, t):\r\n",
    "        if t.value.upper() in self.tokens:\r\n",
    "            t.value = t.value.upper()\r\n",
    "            t.type = t.value\r\n",
    "        return t\r\n",
    "\r\n",
    "    \r\n",
    "    @_(\"\\d+\")\r\n",
    "    def INTEGER(self, t):\r\n",
    "        t.value = int(t.value)\r\n",
    "        return t\r\n",
    "    \r\n",
    "    # @_(\"[\\d.+]\")\r\n",
    "    # def REAL(self, t):\r\n",
    "    #     t.value = float(t.value)\r\n",
    "    #     return t\r\n",
    "    \r\n",
    "    # @_(\"\\n+\")\r\n",
    "    # def ignore_newline(self, t):\r\n",
    "    #     self.lineno += t.value.count('\\n')\r\n",
    "    \r\n",
    "    def error(self, t):\r\n",
    "        print(f\"{t.lineno} - Caracter ilegal '{t.value[0]}'\")\r\n",
    "        self.index += 1\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    lexer = Lexer()\r\n",
    "    env = {}\r\n",
    "    archivo = \"C:\\\\Users\\\\Jhoan\\\\Documents\\\\personal\\\\universidad\\\\compiler\\\\test\\\\test2.txt\"\r\n",
    "    fp = codecs.open(archivo, \"r\", \"utf-8\")\r\n",
    "    data = fp.read()\r\n",
    "    fp.close()\r\n",
    "    \r\n",
    "    for tok in lexer.tokenize(data):\r\n",
    "        print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40866431389e399620475d8caf362561d8ccaeaffd1e6a1080f8502a242d336b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('maq': venv)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}